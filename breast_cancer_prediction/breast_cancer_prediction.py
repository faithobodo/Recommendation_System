# -*- coding: utf-8 -*-
"""breast cancer prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LYfEtPlZWYZelwPpjSt4W7BEoKA3xHdX

### Breast Cancer Prediction
Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image, these include:

* ID number

* Diagnosis (M = malignant, B = benign)

* Ten real-valued features are computed for each cell nucleus:

* radius (mean of distances from center to points on the perimeter)

* texture (standard deviation of gray-scale values) perimeter area

* smoothness (local variation in radius lengths)

* compactness (perimeter^2 / area - 1.0)

* concavity (severity of concave portions of the contour)

* concave points (number of concave portions of the contour) symmetry

* fractal dimension ("coastline approximation" - 1)
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import seaborn as sns
# %matplotlib inline
import matplotlib.pyplot as plt
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import MinMaxScaler, OneHotEncoder
from sklearn.model_selection import train_test_split

df = pd.read_csv("/content/breast-cancer.csv")

df .head()

df.columns, df.shape

# checking for null values
df.isnull().sum()

df.describe()

# to check for the types of diagnosis given to each patient and the count
df.groupby(["diagnosis"])["id"].count()

plt.figure(figsize=(8,8))
y=np.array([357,212])
labels= (["Benign","Malignant"])
plt.pie(y,labels= labels, autopct="%1.1f%%", startangle=90, colors=["g","r"])
plt.title("Distribution of Diagnosis Type")

"""* This simply means that there were 62.7% of women with a diagnosis of benign breast cancer and 37.3% of women with a diagnosis of malignant type of breast cancer."""

# handling null values: the last column has all null values, so we drop it
# df.isnull().sum()
# df.drop(columns= ["Unnamed: 32"], axis=1, inplace=True)

"""## Visualization"""

# A distribution plot
x1 = df.loc[df.diagnosis=='M', ['radius_mean']]
x2 = df.loc[df.diagnosis=='B', ['radius_mean']]

# plot
fig, axes = plt.subplots(1, 3, figsize=(10, 3), sharey=True, dpi=100)
sns.distplot(x1 , color="dodgerblue", ax=axes[0], axlabel='Benign')
sns.distplot(x2 , color="deeppink", ax=axes[1], axlabel='Malignant')
plt.xlim(50,75);

x1 = df.loc[df.diagnosis=='M', ['radius_se']]
x2 = df.loc[df.diagnosis=='B', ['radius_se']]

# plot
fig, axes = plt.subplots(1, 3, figsize=(10, 3), sharey=True, dpi=100)
sns.distplot(x1 , color="dodgerblue", ax=axes[0], axlabel='Benign')
sns.distplot(x2 , color="deeppink", ax=axes[1], axlabel='Malignant')
plt.xlim(50,75);

x1 = df.loc[df.diagnosis=='M', ['radius_worst']]
x2 = df.loc[df.diagnosis=='B', ['radius_worst']]

# plot
fig, axes = plt.subplots(1, 3, figsize=(10, 3), sharey=True, dpi=100)
sns.distplot(x1 , color="dodgerblue", ax=axes[0], axlabel='Benign')
sns.distplot(x2 , color="deeppink", ax=axes[1], axlabel='Malignant')
plt.xlim(50,75);

x1 = df.loc[df.diagnosis=='M', ['texture_mean']]
x2 = df.loc[df.diagnosis=='B', ['texture_mean']]

# plot
fig, axes = plt.subplots(1, 3, figsize=(10, 3), sharey=True, dpi=100)
sns.distplot(x1 , color="dodgerblue", ax=axes[0], axlabel='Benign')
sns.distplot(x2 , color="deeppink", ax=axes[1], axlabel='Malignant')
plt.xlim(50,75);

x1 = df.loc[df.diagnosis=='M', ['texture_se']]
x2 = df.loc[df.diagnosis=='B', ['texture_se']]

# plot
fig, axes = plt.subplots(1, 3, figsize=(10, 3), sharey=True, dpi=100)
sns.distplot(x1 , color="dodgerblue", ax=axes[0], axlabel='Benign')
sns.distplot(x2 , color="deeppink", ax=axes[1], axlabel='Malignant')
plt.xlim(50,75);

x1 = df.loc[df.diagnosis=='M', ['texture_worst']]
x2 = df.loc[df.diagnosis=='B', ['texture_worst']]

# plot
fig, axes = plt.subplots(1, 3, figsize=(10, 3), sharey=True, dpi=100)
sns.distplot(x1 , color="dodgerblue", ax=axes[0], axlabel='Benign')
sns.distplot(x2 , color="deeppink", ax=axes[1], axlabel='Malignant')
plt.xlim(50,75);

x1 = df.loc[df.diagnosis=='M', ['perimeter_mean']]
x2 = df.loc[df.diagnosis=='B', ['perimeter_mean']]

# plot
fig, axes = plt.subplots(1, 3, figsize=(10, 3), sharey=True, dpi=100)
sns.distplot(x1 , color="dodgerblue", ax=axes[0], axlabel='Benign')
sns.distplot(x2 , color="deeppink", ax=axes[1], axlabel='Malignant')
plt.xlim(50,75);


x1 = df.loc[df.diagnosis=='M', ['perimeter_se']]
x2 = df.loc[df.diagnosis=='B', ['perimeter_se']]

# plot
fig, axes = plt.subplots(1, 3, figsize=(10, 3), sharey=True, dpi=100)
sns.distplot(x1 , color="dodgerblue", ax=axes[0], axlabel='Benign')
sns.distplot(x2 , color="deeppink", ax=axes[1], axlabel='Malignant')
plt.xlim(50,75);

x1 = df.loc[df.diagnosis=='M', ['perimeter_worst']]
x2 = df.loc[df.diagnosis=='B', ['perimeter_worst']]

# plot
fig, axes = plt.subplots(1, 3, figsize=(10, 3), sharey=True, dpi=100)
sns.distplot(x1 , color="dodgerblue", ax=axes[0], axlabel='Benign')
sns.distplot(x2 , color="deeppink", ax=axes[1], axlabel='Malignant')
plt.xlim(50,75);

x1 = df.loc[df.diagnosis=='M', ['area_mean']]
x2 = df.loc[df.diagnosis=='B', ['area_mean']]

# plot
fig, axes = plt.subplots(1, 3, figsize=(10, 3), sharey=True, dpi=100)
sns.distplot(x1 , color="dodgerblue", ax=axes[0], axlabel='Benign')
sns.distplot(x2 , color="deeppink", ax=axes[1], axlabel='Malignant')
plt.xlim(50,75);


x1 = df.loc[df.diagnosis=='M', ['area_se']]
x2 = df.loc[df.diagnosis=='B', ['area_se']]

# plot
fig, axes = plt.subplots(1, 3, figsize=(10, 3), sharey=True, dpi=100)
sns.distplot(x1 , color="dodgerblue", ax=axes[0], axlabel='Benign')
sns.distplot(x2 , color="deeppink", ax=axes[1], axlabel='Malignant')
plt.xlim(50,75);


x1 = df.loc[df.diagnosis=='M', ['area_worst']]
x2 = df.loc[df.diagnosis=='B', ['area_worst']]

# plot
fig, axes = plt.subplots(1, 3, figsize=(10, 3), sharey=True, dpi=100)
sns.distplot(x1 , color="dodgerblue", ax=axes[0], axlabel='Benign')
sns.distplot(x2 , color="deeppink", ax=axes[1], axlabel='Malignant')
plt.xlim(50,75);

x1 = df.loc[df.diagnosis=='M', ['smoothness_mean']]
x2 = df.loc[df.diagnosis=='B', ['smoothness_mean']]

# plot
fig, axes = plt.subplots(1, 3, figsize=(10, 3), sharey=True, dpi=100)
sns.distplot(x1 , color="dodgerblue", ax=axes[0], axlabel='Benign')
sns.distplot(x2 , color="deeppink", ax=axes[1], axlabel='Malignant')
plt.xlim(50,75);


x1 = df.loc[df.diagnosis=='M', ['smoothness_se']]
x2 = df.loc[df.diagnosis=='B', ['smoothness_se']]

# plot
fig, axes = plt.subplots(1, 3, figsize=(10, 3), sharey=True, dpi=100)
sns.distplot(x1 , color="dodgerblue", ax=axes[0], axlabel='Benign')
sns.distplot(x2 , color="deeppink", ax=axes[1], axlabel='Malignant')
plt.xlim(50,75);


x1 = df.loc[df.diagnosis=='M', ['smoothness_worst']]
x2 = df.loc[df.diagnosis=='B', ['smoothness_worst']]

# plot
fig, axes = plt.subplots(1, 3, figsize=(10, 3), sharey=True, dpi=100)
sns.distplot(x1 , color="dodgerblue", ax=axes[0], axlabel='Benign')
sns.distplot(x2 , color="deeppink", ax=axes[1], axlabel='Malignant')
plt.xlim(50,75);

x1 = df.loc[df.diagnosis=='M', ['compactness_mean']]
x2 = df.loc[df.diagnosis=='B', ['compactness_mean']]

# plot
fig, axes = plt.subplots(1, 3, figsize=(10, 3), sharey=True, dpi=100)
sns.distplot(x1 , color="dodgerblue", ax=axes[0], axlabel='Benign')
sns.distplot(x2 , color="deeppink", ax=axes[1], axlabel='Malignant')
plt.xlim(50,75);


x1 = df.loc[df.diagnosis=='M', ['compactness_se']]
x2 = df.loc[df.diagnosis=='B', ['compactness_se']]

# plot
fig, axes = plt.subplots(1, 3, figsize=(10, 3), sharey=True, dpi=100)
sns.distplot(x1 , color="dodgerblue", ax=axes[0], axlabel='Benign')
sns.distplot(x2 , color="deeppink", ax=axes[1], axlabel='Malignant')
plt.xlim(50,75);


x1 = df.loc[df.diagnosis=='M', ['compactness_worst']]
x2 = df.loc[df.diagnosis=='B', ['compactness_worst']]

# plot
fig, axes = plt.subplots(1, 3, figsize=(10, 3), sharey=True, dpi=100)
sns.distplot(x1 , color="dodgerblue", ax=axes[0], axlabel='Benign')
sns.distplot(x2 , color="deeppink", ax=axes[1], axlabel='Malignant')
plt.xlim(50,75);

x1 = df.loc[df.diagnosis=='M', ['concavity_mean']]
x2 = df.loc[df.diagnosis=='B', ['concavity_mean']]

# plot
fig, axes = plt.subplots(1, 3, figsize=(10, 3), sharey=True, dpi=100)
sns.distplot(x1 , color="dodgerblue", ax=axes[0], axlabel='Benign')
sns.distplot(x2 , color="deeppink", ax=axes[1], axlabel='Malignant')
plt.xlim(50,75);

x1 = df.loc[df.diagnosis=='M', ['concavity_se']]
x2 = df.loc[df.diagnosis=='B', ['concavity_se']]

# plot
fig, axes = plt.subplots(1, 3, figsize=(10, 3), sharey=True, dpi=100)
sns.distplot(x1 , color="dodgerblue", ax=axes[0], axlabel='Benign')
sns.distplot(x2 , color="deeppink", ax=axes[1], axlabel='Malignant')
plt.xlim(50,75);

x1 = df.loc[df.diagnosis=='M', ['concavity_worst']]
x2 = df.loc[df.diagnosis=='B', ['concavity_worst']]

# plot
fig, axes = plt.subplots(1, 3, figsize=(10, 3), sharey=True, dpi=100)
sns.distplot(x1 , color="dodgerblue", ax=axes[0], axlabel='Benign')
sns.distplot(x2 , color="deeppink", ax=axes[1], axlabel='Malignant')
plt.xlim(50,75);

x1 = df.loc[df.diagnosis=='M', ['concave points_mean']]
x2 = df.loc[df.diagnosis=='B', ['concave points_mean']]

# plot
fig, axes = plt.subplots(1, 3, figsize=(10, 3), sharey=True, dpi=100)
sns.distplot(x1 , color="dodgerblue", ax=axes[0], axlabel='Benign')
sns.distplot(x2 , color="deeppink", ax=axes[1], axlabel='Malignant')
plt.xlim(50,75);

x1 = df.loc[df.diagnosis=='M', ['concave points_se']]
x2 = df.loc[df.diagnosis=='B', ['concave points_se']]

# plot
fig, axes = plt.subplots(1, 3, figsize=(10, 3), sharey=True, dpi=100)
sns.distplot(x1 , color="dodgerblue", ax=axes[0], axlabel='Benign')
sns.distplot(x2 , color="deeppink", ax=axes[1], axlabel='Malignant')
plt.xlim(50,75);

x1 = df.loc[df.diagnosis=='M', ['concave points_worst']]
x2 = df.loc[df.diagnosis=='B', ['concave points_worst']]

# plot
fig, axes = plt.subplots(1, 3, figsize=(10, 3), sharey=True, dpi=100)
sns.distplot(x1 , color="dodgerblue", ax=axes[0], axlabel='Benign')
sns.distplot(x2 , color="deeppink", ax=axes[1], axlabel='Malignant')
plt.xlim(50,75);

x1 = df.loc[df.diagnosis=='M', ['symmetry_mean']]
x2 = df.loc[df.diagnosis=='B', ['symmetry_mean']]

# plot
fig, axes = plt.subplots(1, 3, figsize=(10, 3), sharey=True, dpi=100)
sns.distplot(x1 , color="dodgerblue", ax=axes[0], axlabel='Benign')
sns.distplot(x2 , color="deeppink", ax=axes[1], axlabel='Malignant')
plt.xlim(50,75);

x1 = df.loc[df.diagnosis=='M', ['symmetry_se']]
x2 = df.loc[df.diagnosis=='B', ['symmetry_se']]

# plot
fig, axes = plt.subplots(1, 3, figsize=(10, 3), sharey=True, dpi=100)
sns.distplot(x1 , color="dodgerblue", ax=axes[0], axlabel='Benign')
sns.distplot(x2 , color="deeppink", ax=axes[1], axlabel='Malignant')
plt.xlim(50,75);

x1 = df.loc[df.diagnosis=='M', ['symmetry_worst']]
x2 = df.loc[df.diagnosis=='B', ['symmetry_worst']]

# plot
fig, axes = plt.subplots(1, 3, figsize=(10, 3), sharey=True, dpi=100)
sns.distplot(x1 , color="dodgerblue", ax=axes[0], axlabel='Benign')
sns.distplot(x2 , color="deeppink", ax=axes[1], axlabel='Malignant')
plt.xlim(50,75);

x1 = df.loc[df.diagnosis=='M', ['fractal_dimension_mean']]
x2 = df.loc[df.diagnosis=='B', ['fractal_dimension_mean']]

# plot
fig, axes = plt.subplots(1, 3, figsize=(10, 3), sharey=True, dpi=100)
sns.distplot(x1 , color="dodgerblue", ax=axes[0], axlabel='Benign')
sns.distplot(x2 , color="deeppink", ax=axes[1], axlabel='Malignant')
plt.xlim(50,75);

x1 = df.loc[df.diagnosis=='M', ['fractal_dimension_se']]
x2 = df.loc[df.diagnosis=='B', ['fractal_dimension_se']]

# plot
fig, axes = plt.subplots(1, 3, figsize=(10, 3), sharey=True, dpi=100)
sns.distplot(x1 , color="dodgerblue", ax=axes[0], axlabel='Benign')
sns.distplot(x2 , color="deeppink", ax=axes[1], axlabel='Malignant')
plt.xlim(50,75);

x1 = df.loc[df.diagnosis=='M', ['fractal_dimension_worst']]
x2 = df.loc[df.diagnosis=='B', ['fractal_dimension_worst']]

# plot
fig, axes = plt.subplots(1, 3, figsize=(10, 3), sharey=True, dpi=100)
sns.distplot(x1 , color="dodgerblue", ax=axes[0], axlabel='Benign')
sns.distplot(x2 , color="deeppink", ax=axes[1], axlabel='Malignant')
plt.xlim(50,75);

# A correlation plot to show highly correlated features
plt.figure(figsize=(30,15))
sns.heatmap(df.corr(),annot=True, cmap ='coolwarm')

"""#### how features are correlated to one another
* radius worst vs radius mean
* perimeter worst vs radius mean
* area worst vs radius mean
* texture worst vs texture mean
* radius worst vs perimeter mean
* perimeter worst vs perimeter mean
* area worst vs perimeter mean
* radius worst vs area mean
* perimeter worst vs area mean
* perimeter worst vs area mean
* area worst vs area mean
* perimeter worst vs radius worst
* area worst vs radius worst
* area worst vs perimeter worst
* area se vs radius se
* area se vs peimeter se
* perimeter mean vs radius mean
* area mean vs radius mean
* area mean vs perimter mean

#### Positively Correlated Features
* In the scatter plot, the graph is to move from B to M, to show that the features are positively correlated.
"""

# using a scatter plot to check the correlation betwen each of theses positively correlative features
plt.figure(figsize=(15,8))

plt.subplot(221)
sns.scatterplot(x = df['radius_worst'], y = df['radius_mean'], hue = "diagnosis",
    data = df, palette = "flare", edgecolor="None")
plt.title('radius worst vs radius mean')

plt.subplot(222)
sns.scatterplot(x = df['perimeter_worst'], y = df['radius_mean'], hue = "diagnosis",
    data = df, palette = "flare", edgecolor="None")
plt.title('perimeter worst vs radius mean')

plt.figure(figsize=(15,8))
plt.subplot(221)
sns.scatterplot(x=df["area_worst"], y=df["radius_mean"],hue="diagnosis", data=df, palette="flare", edgecolor="None")
plt.title("area worst vs radius mean")

plt.subplot(222)
sns.scatterplot(x=df["texture_worst"], y=df["texture_mean"],hue="diagnosis", data=df, palette="flare", edgecolor="None")
plt.title("texture worst vs texture mean")

plt.figure(figsize=(15,8))
plt.subplot(221)

sns.scatterplot(x=df["radius_worst"], y=df["perimeter_mean"],hue="diagnosis", data=df, palette="flare", edgecolor="None")
plt.title("radius worst vs perimeter mean")

plt.subplot(222)
sns.scatterplot(x=df["perimeter_worst"], y=df["perimeter_mean"],hue="diagnosis", data=df, palette="flare", edgecolor="None")
plt.title("perimeter worst vs perimeter mean")

plt.figure(figsize=(15,8))
plt.subplot(221)
sns.scatterplot(x=df["area_worst"], y=df["perimeter_mean"],hue="diagnosis", data=df, palette="flare", edgecolor="None")
plt.title("area worst vs perimeter mean")

plt.subplot(222)
sns.scatterplot(x=df["radius_worst"], y=df["area_mean"],hue="diagnosis", data=df, palette="flare", edgecolor="None")
plt.title("radius worst vs area mean")

plt.figure(figsize=(15,8))
plt.subplot(221)
sns.scatterplot(x=df["perimeter_worst"], y=df["area_mean"],hue="diagnosis", data=df, palette="flare", edgecolor="None")
plt.title("perimeter worst vs area mean")

plt.subplot(222)
sns.scatterplot(x=df["area_worst"], y=df["area_mean"],hue="diagnosis", data=df, palette="flare", edgecolor="None")
plt.title("area worst vs area mean")

plt.figure(figsize=(15,8))
plt.subplot(221)
sns.scatterplot(x=df["perimeter_worst"], y=df["radius_worst"],hue="diagnosis", data=df, palette="flare", edgecolor="None")
plt.title("perimeter worst vs radius worst")

plt.subplot(222)
sns.scatterplot(x=df["area_worst"], y=df["radius_worst"],hue="diagnosis", data=df, palette="flare", edgecolor="None")
plt.title("area worst vs radius worst")

plt.figure(figsize=(15,8))
plt.subplot(221)
sns.scatterplot(x=df["area_worst"], y=df["perimeter_worst"],hue="diagnosis", data=df, palette="flare", edgecolor="None")
plt.title("area worst vs perimeter worst")

plt.subplot(222)
sns.scatterplot(x=df["area_se"], y=df["radius_se"],hue="diagnosis", data=df, palette="flare", edgecolor="None")
plt.title("area se vs radius se")

plt.figure(figsize=(15,8))
plt.subplot(221)
sns.scatterplot(x=df["area_se"], y=df["perimeter_se"],hue="diagnosis", data=df, palette="flare", edgecolor="None")
plt.title("area se vs perimeter se")

plt.subplot(222)
sns.scatterplot(x=df["perimeter_mean"], y=df["radius_mean"],hue="diagnosis", data=df, palette="flare", edgecolor="None")
plt.title("perimeter mean vs radius mean")

plt.figure(figsize=(15,8))
plt.subplot(221)
sns.scatterplot(x=df["area_mean"], y=df["radius_mean"],hue="diagnosis", data=df, palette="flare", edgecolor="None")
plt.title("area mean vs radius mean")

plt.subplot(222)
sns.scatterplot(x=df["area_mean"], y=df["perimeter_mean"],hue="diagnosis", data=df, palette="flare", edgecolor="None")
plt.title("area mean vs perimeter mean")

"""#### Negatively Correlated Features
* In the scatter plot, when it moves from M to B it shows that the features are negatively correlated.
"""

plt.figure(figsize=(15,8))
plt.subplot(221)
sns.scatterplot(x=df["radius_worst"], y=df["smoothness_se"],hue="diagnosis", data=df, palette="flare", edgecolor="None")
plt.title("radius worst vs smoothness se")

plt.subplot(222)
sns.scatterplot(x=df["texture_worst"], y=df["symmetry_se"],hue="diagnosis", data=df, palette="flare", edgecolor="None")
plt.title("texture worst vs symmetry se")

"""#### Uncorrelated Features
* In the plot the dots for both Malignant and Benign are random and overlapped on one another, which depicts that the features are not correlated
"""

plt.figure(figsize=(15,8))
plt.subplot(221)
sns.scatterplot(x=df["texture_worst"], y=df["symmetry_mean"],hue="diagnosis", data=df, palette="flare", edgecolor="None")
plt.title("texture worst vs symmetry mean")

plt.subplot(222)
sns.scatterplot(x=df["smoothness_worst"], y=df["radius_mean"],hue="diagnosis", data=df, palette="flare", edgecolor="None")
plt.title("area worst vs radius mean")

sns.scatterplot(x = df['id'], y = df['radius_mean'], hue = "diagnosis",
    data = df, palette = "flare", edgecolor="None")
plt.title('id vs radius mean')

# from matplotlib import model_feature_importances
# # feat_importances = pd.Series(model.feature_importances_, index=X.columns)
# # feat_importances.nlargest(20).plot(kind='barh')

# plt.bar(range(len(model.feature_importances_)), model.feature_importances_)
# plt.show()

"""#### Preparing the dataset for training and modelling"""

# Re-arranging the columns for easy slicing
# selecting the highly correlated features as input for training
data = df.reindex(columns=['diagnosis','id', 'smoothness_mean', 'compactness_mean', 'concavity_mean',
       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean', 'texture_se',
       'smoothness_se','compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',
       'fractal_dimension_se', 'smoothness_worst','compactness_worst', 'concavity_worst', 
       'concave points_worst','symmetry_worst', 'fractal_dimension_worst','perimeter_se', 
       'area_se','perimeter_worst', 'area_worst','radius_mean','texture_mean','perimeter_mean',
       'area_mean','radius_worst', 'texture_worst','radius_se'])

data.columns

input_cols, target_cols=data.columns[1:], data.columns[:1]
input_dfs, target_dfs= data.columns[1:].copy(), data.columns[:1].copy()

# for encoding all the target variable
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
encoded_target = df[target_cols].apply(le.fit_transform)

#casting all the np.number to a new list
numeric_cols = data[input_cols].select_dtypes(include=np.number).columns.tolist()

# to normalize the input columns for training
imputer = SimpleImputer().fit(data[numeric_cols])
data[numeric_cols] = imputer.transform(data[numeric_cols])
scaler = MinMaxScaler().fit(data[numeric_cols])
normalized_input = scaler.transform(data[numeric_cols])

#splitting data
X_train, X_test, Y_train, Y_test = train_test_split(normalized_input,encoded_target,test_size=0.2, random_state=42)

"""### Logistic Regression"""

# training using logistic regression
lr= LogisticRegression()

model = lr.fit(X_train,Y_train)

lr_accuracy=lr.score(X_test,Y_test)
lr_accuracy

importance = model.coef_[0]

for i,v in enumerate(importance):
  print('Feature: %0d, Score: %.5f' % (i,v))

plt.bar([x for x in range(len(importance))], importance)
plt.show()

Y_pred=lr.predict(X_test)
Y_pred

from sklearn import metrics
lr_cnf_matrix = metrics.confusion_matrix(Y_test, Y_pred)
lr_cnf_matrix

class_names=[0,1] # name  of classes
fig, ax = plt.subplots()

tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)

# create heatmap
sns.heatmap(pd.DataFrame(lr_cnf_matrix), annot=True, cmap="YlGnBu" ,fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Confusion matrix', y=1.1)
plt.ylabel('Actual label')
plt.xlabel('Predicted label')

log_accuracy= metrics.accuracy_score(Y_test, y_pred)
log_precision = metrics.precision_score(Y_test, y_pred)
log_recall = metrics.recall_score(Y_test, y_pred)

print("Accuracy:",metrics.accuracy_score(Y_test, y_pred))
print("Precision:",metrics.precision_score(Y_test, y_pred))
print("Recall:",metrics.recall_score(Y_test, y_pred))

# using the ROC Curve to check for the true positive rate against the false negative rate
y_pred_proba = log.predict_proba(x_test)[::,1]
fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)
auc = metrics.roc_auc_score(y_test, y_pred_proba)
plt.plot(fpr,tpr,label="data 1, auc="+str(auc))
plt.legend(loc=4)
plt.show()

"""### Support Vector Machine"""

from sklearn.svm import SVC
classifier = SVC(kernel='rbf', random_state = 1)
svc_model=classifier.fit(X_train,Y_train)

from sklearn.metrics import confusion_matrix,f1_score,accuracy_score,classification_report
from sklearn import svm
trainedsvm = svm.SVC().fit(X_train, Y_train)
predictionsvm = trainedsvm.predict(X_test)
print(confusion_matrix(Y_test,predictionsvm))
print(classification_report(Y_test,predictionsvm))

Y_pred = classifier.predict(X_test)
Y_pred

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(Y_test,Y_pred)
accuracy = float(cm.diagonal().sum())/len(y_test)
print("\nAccuracy Of SVM For The Given Dataset : ", accuracy)

"""#### K-Nearest Neighbours"""

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=3)

knn_model=knn.fit(X_train,Y_train)

print(knn.predict(X_test))

knn.score(X_test,Y_test)

"""#### Decision Tree Classifier"""

from sklearn.tree import DecisionTreeClassifier 
from sklearn import metrics

clf= DecisionTreeClassifier()

clf=clf.fit(X_train,Y_train)

clf.score(X_test,Y_test)

"""* So far logistic regression gives us the best, model prediction, with an accuracy of 0.98, so we train subsequent datasets entered using logistic regression model

### Saving and Load Model
"""

import pickle

# Save the trained model as a pickle string.
saved_model = pickle.dumps(lr)

# Load the pickled model
lr_from_pickle = pickle.loads(saved_model)

# Use the loaded pickled model to make predictions
# lr_from_pickle.predict(X_test)